{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc014649",
   "metadata": {},
   "source": [
    "# LowerCasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b489cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d35b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_review = pd.read_csv('movieReviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ae4091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date of Review</th>\n",
       "      <th>User</th>\n",
       "      <th>Usefulness Vote</th>\n",
       "      <th>Total Votes</th>\n",
       "      <th>User's Rating out of 10</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 May 2019</td>\n",
       "      <td>Paynebyname</td>\n",
       "      <td>1481</td>\n",
       "      <td>2771</td>\n",
       "      <td>4</td>\n",
       "      <td>The writers got carried away, the directors ov...</td>\n",
       "      <td>I've just come from watching Endgame and I mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 May 2019</td>\n",
       "      <td>jtindahouse</td>\n",
       "      <td>75</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "      <td>Time travel is such a lazy way to write stories</td>\n",
       "      <td>Only a month or so back I was talking to a fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13 May 2019</td>\n",
       "      <td>arclinecreative</td>\n",
       "      <td>100</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "      <td>Overrated and full of filler</td>\n",
       "      <td>Continuity? 350M budget and no one looking ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 August 2019</td>\n",
       "      <td>RetroRick</td>\n",
       "      <td>99</td>\n",
       "      <td>169</td>\n",
       "      <td>3</td>\n",
       "      <td>downbeat, overblown &amp; so so long. Cuts all you...</td>\n",
       "      <td>Maybe I would have enjoyed this more if I were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13 December 2021</td>\n",
       "      <td>ACollegeStudent</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>Not as good as infinity war but a great movie</td>\n",
       "      <td>Rating: 8.6Not as good as Infinity war pacing-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date of Review             User  Usefulness Vote  Total Votes  \\\n",
       "0        4 May 2019      Paynebyname             1481         2771   \n",
       "1        6 May 2019      jtindahouse               75          127   \n",
       "2       13 May 2019  arclinecreative              100          170   \n",
       "3     3 August 2019        RetroRick               99          169   \n",
       "4  13 December 2021  ACollegeStudent               27           41   \n",
       "\n",
       "  User's Rating out of 10                                       Review Title  \\\n",
       "0                       4  The writers got carried away, the directors ov...   \n",
       "1                       4    Time travel is such a lazy way to write stories   \n",
       "2                       3                       Overrated and full of filler   \n",
       "3                       3  downbeat, overblown & so so long. Cuts all you...   \n",
       "4                       8      Not as good as infinity war but a great movie   \n",
       "\n",
       "                                              Review  \n",
       "0  I've just come from watching Endgame and I mus...  \n",
       "1  Only a month or so back I was talking to a fri...  \n",
       "2  Continuity? 350M budget and no one looking ove...  \n",
       "3  Maybe I would have enjoyed this more if I were...  \n",
       "4  Rating: 8.6Not as good as Infinity war pacing-...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d10e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_review['Review'] = movies_review['Review'][0].lower()  # Single row task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae9613f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date of Review</th>\n",
       "      <th>User</th>\n",
       "      <th>Usefulness Vote</th>\n",
       "      <th>Total Votes</th>\n",
       "      <th>User's Rating out of 10</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>27 May 2022</td>\n",
       "      <td>joe_jr</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Biggest Fail of the Avengers Series</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date of Review    User  Usefulness Vote  Total Votes  \\\n",
       "3681    27 May 2022  joe_jr                3            5   \n",
       "\n",
       "     User's Rating out of 10                         Review Title  \\\n",
       "3681                       3  Biggest Fail of the Avengers Series   \n",
       "\n",
       "                                                 Review  \n",
       "3681  i've just come from watching endgame and i mus...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_review.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16202985",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_review['User'] = movies_review['User'].str.lower() # Appply all reviews rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7df11d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date of Review</th>\n",
       "      <th>User</th>\n",
       "      <th>Usefulness Vote</th>\n",
       "      <th>Total Votes</th>\n",
       "      <th>User's Rating out of 10</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 May 2019</td>\n",
       "      <td>paynebyname</td>\n",
       "      <td>1481</td>\n",
       "      <td>2771</td>\n",
       "      <td>4</td>\n",
       "      <td>The writers got carried away, the directors ov...</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 May 2019</td>\n",
       "      <td>jtindahouse</td>\n",
       "      <td>75</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "      <td>Time travel is such a lazy way to write stories</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13 May 2019</td>\n",
       "      <td>arclinecreative</td>\n",
       "      <td>100</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "      <td>Overrated and full of filler</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 August 2019</td>\n",
       "      <td>retrorick</td>\n",
       "      <td>99</td>\n",
       "      <td>169</td>\n",
       "      <td>3</td>\n",
       "      <td>downbeat, overblown &amp; so so long. Cuts all you...</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13 December 2021</td>\n",
       "      <td>acollegestudent</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>Not as good as infinity war but a great movie</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>1 June 2019</td>\n",
       "      <td>ismael_rivera</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>A reward to fans that have been since the begi...</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>27 April 2019</td>\n",
       "      <td>barbarasokoloski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Fun and well-done</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>25 April 2019</td>\n",
       "      <td>jfelipepoll</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Just Wao!!</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>25 April 2019</td>\n",
       "      <td>louikelemen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Endgame is for the Fans</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9513</th>\n",
       "      <td>26 April 2019</td>\n",
       "      <td>kayodeodusanya</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>BADASS!!!</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9514 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date of Review              User  Usefulness Vote  Total Votes  \\\n",
       "0           4 May 2019       paynebyname             1481         2771   \n",
       "1           6 May 2019       jtindahouse               75          127   \n",
       "2          13 May 2019   arclinecreative              100          170   \n",
       "3        3 August 2019         retrorick               99          169   \n",
       "4     13 December 2021   acollegestudent               27           41   \n",
       "...                ...               ...              ...          ...   \n",
       "9509       1 June 2019     ismael_rivera                0            2   \n",
       "9510     27 April 2019  barbarasokoloski                0            0   \n",
       "9511     25 April 2019       jfelipepoll                0            2   \n",
       "9512     25 April 2019       louikelemen                0            0   \n",
       "9513     26 April 2019    kayodeodusanya                0            2   \n",
       "\n",
       "     User's Rating out of 10  \\\n",
       "0                          4   \n",
       "1                          4   \n",
       "2                          3   \n",
       "3                          3   \n",
       "4                          8   \n",
       "...                      ...   \n",
       "9509                       9   \n",
       "9510                       8   \n",
       "9511                      10   \n",
       "9512                      10   \n",
       "9513                       9   \n",
       "\n",
       "                                           Review Title  \\\n",
       "0     The writers got carried away, the directors ov...   \n",
       "1       Time travel is such a lazy way to write stories   \n",
       "2                          Overrated and full of filler   \n",
       "3     downbeat, overblown & so so long. Cuts all you...   \n",
       "4         Not as good as infinity war but a great movie   \n",
       "...                                                 ...   \n",
       "9509  A reward to fans that have been since the begi...   \n",
       "9510                                  Fun and well-done   \n",
       "9511                                         Just Wao!!   \n",
       "9512                            Endgame is for the Fans   \n",
       "9513                                          BADASS!!!   \n",
       "\n",
       "                                                 Review  \n",
       "0     i've just come from watching endgame and i mus...  \n",
       "1     i've just come from watching endgame and i mus...  \n",
       "2     i've just come from watching endgame and i mus...  \n",
       "3     i've just come from watching endgame and i mus...  \n",
       "4     i've just come from watching endgame and i mus...  \n",
       "...                                                 ...  \n",
       "9509  i've just come from watching endgame and i mus...  \n",
       "9510  i've just come from watching endgame and i mus...  \n",
       "9511  i've just come from watching endgame and i mus...  \n",
       "9512  i've just come from watching endgame and i mus...  \n",
       "9513  i've just come from watching endgame and i mus...  \n",
       "\n",
       "[9514 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b29c9",
   "metadata": {},
   "source": [
    "# HTMLtag Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ac5626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    # Regular expression to match HTML tags\n",
    "    html_tag_pattern = r'<[^>]*>'\n",
    "    \n",
    "    # Use regex to remove HTML tags from the text\n",
    "    clean_text = re.sub(html_tag_pattern, '', text)\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ee93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "htmml = '''<h1>OpenAI is an American artificial intelligence (AI) research laboratory consisting of the non-profit</h1>\n",
    "<p>OpenAI and its for-profit subsidiary corporation OpenAI Limited Partnership. OpenAI conducts \n",
    "AI research with the declared intention of developing \"safe and beneficial\" artificial general intelligence, \n",
    "which it defines as </p>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192d1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI is an American artificial intelligence (AI) research laboratory consisting of the non-profit\n",
      "OpenAI and its for-profit subsidiary corporation OpenAI Limited Partnership. OpenAI conducts \n",
      "AI research with the declared intention of developing \"safe and beneficial\" artificial general intelligence, \n",
      "which it defines as \n"
     ]
    }
   ],
   "source": [
    "rem_tag = remove_html_tags(htmml)\n",
    "print(rem_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27490d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Html':htmml}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c77c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_dataframes = pd.DataFrame(data,index=['Tag1','Tag2','Tag3','Tag4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "943a8094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tag1</th>\n",
       "      <td>&lt;h1&gt;OpenAI is an American artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag2</th>\n",
       "      <td>&lt;h1&gt;OpenAI is an American artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag3</th>\n",
       "      <td>&lt;h1&gt;OpenAI is an American artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag4</th>\n",
       "      <td>&lt;h1&gt;OpenAI is an American artificial intellige...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Html\n",
       "Tag1  <h1>OpenAI is an American artificial intellige...\n",
       "Tag2  <h1>OpenAI is an American artificial intellige...\n",
       "Tag3  <h1>OpenAI is an American artificial intellige...\n",
       "Tag4  <h1>OpenAI is an American artificial intellige..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10c1a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_dataframes['Html']= html_dataframes['Html'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c5df7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tag1</th>\n",
       "      <td>OpenAI is an American artificial intelligence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag2</th>\n",
       "      <td>OpenAI is an American artificial intelligence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag3</th>\n",
       "      <td>OpenAI is an American artificial intelligence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag4</th>\n",
       "      <td>OpenAI is an American artificial intelligence ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Html\n",
       "Tag1  OpenAI is an American artificial intelligence ...\n",
       "Tag2  OpenAI is an American artificial intelligence ...\n",
       "Tag3  OpenAI is an American artificial intelligence ...\n",
       "Tag4  OpenAI is an American artificial intelligence ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa8fddf",
   "metadata": {},
   "source": [
    "# Removing URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f116857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    clean_text = re.sub(url_pattern, '', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0840fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text1 = 'Hello how are you http://www.google.com/grow.google'\n",
    "Text2 = 'AI is new Revolution www.yahoo.com'\n",
    "Text3 = 'Chance to Give something new http://www.bing.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf1eb90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_dataframes = pd.DataFrame(data=[Text1,Text2,Text3],columns=['Itemwithlinks'],index=['1','2','3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3a52004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Itemwithlinks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello how are you http://www.google.com/grow.g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI is new Revolution www.yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chance to Give something new http://www.bing.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Itemwithlinks\n",
       "1  Hello how are you http://www.google.com/grow.g...\n",
       "2                 AI is new Revolution www.yahoo.com\n",
       "3   Chance to Give something new http://www.bing.com"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dc66d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_dataframes['Itemwithlinks']=link_dataframes['Itemwithlinks'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "899d1c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Itemwithlinks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello how are you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI is new Revolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chance to Give something new</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Itemwithlinks\n",
       "1             Hello how are you \n",
       "2          AI is new Revolution \n",
       "3  Chance to Give something new "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7bab7a",
   "metadata": {},
   "source": [
    "# Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31f3606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    clean_text = text.translate(translator)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1da0a83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4b0daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Name\": ['hyphen','dash','question mark','exclamation mark exclamation point (AmE)'],\n",
    "        \"Example\": ['This is a rather out-of-date book.','In each town—London, Paris and Rome—we stayed in youth hostels.','Where is Shangri-La?','''\"Help!\" she cried. \"I can't swim!\"''']\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d6d85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_dataframes = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fee37754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyphen</td>\n",
       "      <td>This is a rather out-of-date book.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dash</td>\n",
       "      <td>In each town—London, Paris and Rome—we stayed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question mark</td>\n",
       "      <td>Where is Shangri-La?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exclamation mark exclamation point (AmE)</td>\n",
       "      <td>\"Help!\" she cried. \"I can't swim!\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name  \\\n",
       "0                                    hyphen   \n",
       "1                                      dash   \n",
       "2                             question mark   \n",
       "3  exclamation mark exclamation point (AmE)   \n",
       "\n",
       "                                             Example  \n",
       "0                 This is a rather out-of-date book.  \n",
       "1  In each town—London, Paris and Rome—we stayed ...  \n",
       "2                               Where is Shangri-La?  \n",
       "3                 \"Help!\" she cried. \"I can't swim!\"  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47ce22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Punctuation\n",
    "punc_dataframes['Example']=punc_dataframes['Example'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdfb4229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hyphen</td>\n",
       "      <td>This is a rather outofdate book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dash</td>\n",
       "      <td>In each town—London Paris and Rome—we stayed i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question mark</td>\n",
       "      <td>Where is ShangriLa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exclamation mark exclamation point (AmE)</td>\n",
       "      <td>Help she cried I cant swim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name  \\\n",
       "0                                    hyphen   \n",
       "1                                      dash   \n",
       "2                             question mark   \n",
       "3  exclamation mark exclamation point (AmE)   \n",
       "\n",
       "                                             Example  \n",
       "0                    This is a rather outofdate book  \n",
       "1  In each town—London Paris and Rome—we stayed i...  \n",
       "2                                 Where is ShangriLa  \n",
       "3                         Help she cried I cant swim  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8154ee4",
   "metadata": {},
   "source": [
    "# Chat Word Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07c7a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    \"afaik\": \"as far as I know\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bbl\": \"be back later\",\n",
    "    \"bfn\": \"bye for now\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"cu\": \"see you\",\n",
    "    \"cya\": \"see you later\",\n",
    "    \"fomo\": \"fear of missing out\",\n",
    "    \"ftw\": \"for the win\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"idc\": \"I don't care\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"kthxbye\": \"okay, thanks, bye\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"nbd\": \"no big deal\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"nsfw\": \"not safe for work\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"omw\": \"on my way\",\n",
    "    \"otp\": \"one true pairing\",\n",
    "    \"ppl\": \"people\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"srsly\": \"seriously\",\n",
    "    \"tmi\": \"too much information\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"wb\": \"welcome back\",\n",
    "    \"wtf\": \"what the fudge\",\n",
    "    \"wyd\": \"what are you doing\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"yw\": \"you're welcome\",\n",
    "    \"zzz\": \"sleeping or bored\",\n",
    "    # Add more chat words and their expansions as needed\n",
    "    \"gr8\": \"great\",\n",
    "    \"cu2nite\": \"see you tonight\",\n",
    "    \"omg\": \"oh my gosh\",\n",
    "    \"ttylxox\": \"talk to you later, hugs and kisses\",\n",
    "    \"btw\": \"between\",\n",
    "    \"lolz\": \"laugh out loud\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"g2g\": \"got to go\",\n",
    "    \"idc\": \"I don't care\",\n",
    "    \"bbs\": \"be back soon\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"roflmao\": \"rolling on the floor laughing my ass off\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"l8\": \"late\",\n",
    "    \"g8\": \"great\",\n",
    "    \"b4\": \"before\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"w8\": \"wait\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"bff\": \"best friends forever\",\n",
    "    \"fomo\": \"fear of missing out\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"ty\": \"thank you\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"hbu\": \"how about you\",\n",
    "    \"wb\": \"welcome back\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"wth\": \"what the heck\",\n",
    "    \"bfn\": \"bye for now\",\n",
    "    \"btdubs\": \"by the way\",\n",
    "    \"omw\": \"on my way\",\n",
    "    \"omg\": \"oh my goodness\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"nbd\": \"no big deal\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"ttys\": \"talk to you soon\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"yep\": \"yes\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"bc\": \"because\",\n",
    "    \"omg\": \"oh my gosh\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"omw\": \"on my way\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"bbs\": \"be back soon\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"hbu\": \"how about you\",\n",
    "    \"wb\": \"welcome back\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"ttylxox\": \"talk to you later, hugs and kisses\",\n",
    "    \"idc\": \"I don't care\",\n",
    "    \"w8\": \"wait\",\n",
    "    \"l8\": \"late\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"bfn\": \"bye for now\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"cu\": \"see you\",\n",
    "    \"cya\": \"see you later\",\n",
    "    \"fomo\": \"fear of missing out\",\n",
    "    \"ftw\": \"for the win\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"idc\": \"I don't care\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"irl\": \"in real life\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"kthxbye\": \"okay, thanks, bye\",\n",
    "    \"lmao\": \"laughing my ass off\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"lmk\": \"let me know\",\n",
    "    \"nbd\": \"no big deal\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"nsfw\": \"not safe for work\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"omw\": \"on my way\",\n",
    "    \"otp\": \"one true pairing\",\n",
    "    \"ppl\": \"people\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"srsly\": \"seriously\",\n",
    "    \"tmi\": \"too much information\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"wb\": \"welcome back\",\n",
    "    \"wtf\": \"what the fudge\",\n",
    "    \"wyd\": \"what are you doing\",\n",
    "    \"yolo\": \"you only live once\",\n",
    "    \"yw\": \"you're welcome\",\n",
    "    \"zzz\": \"sleeping or bored\",\n",
    "    # Add more chat words and their expansions as needed\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c574a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_word_treatment(text):\n",
    "    words = text.split()\n",
    "    treated_words = [chat_words.get(word.lower(), word) for word in words]\n",
    "    clean_text = \" \".join(treated_words)\n",
    "    \n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d766e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okk bye for now\n",
      "Hay you're welcome\n",
      "hello guys what are you doing\n",
      "i am talk to you later\n",
      "what seriously\n",
      "Please Excuse me let me know things things\n"
     ]
    }
   ],
   "source": [
    "print(chat_word_treatment('okk bfn'))\n",
    "print(chat_word_treatment('Hay yw'))\n",
    "print(chat_word_treatment('hello guys wyd'))\n",
    "print(chat_word_treatment('i am ttyl'))\n",
    "print(chat_word_treatment('what srsly'))\n",
    "print(chat_word_treatment('Please Excuse me lmk things things'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9be7b",
   "metadata": {},
   "source": [
    "# SpellChecking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82e87ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e81f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text_1 = 'Thier is a beutiful sunet at the beech'\n",
    "incorrect_text_2 ='I cant belive he wnt to the resturant by himself.'\n",
    "incorrect_text_3 ='She alwayes maks delisious choclate chip cookies.'\n",
    "incorrect_text_4 ='Tomorow we will go to the musuem to see the exibit.'\n",
    "incorrect_text_5 ='My freind has a bueatiful gardin in her back yard.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05bb1b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Her is a beautiful sunset at the beech\n",
      "I can believe he went to the restaurant by himself.\n",
      "The always make delirious chocolate chip colonies.\n",
      "Tomorrow we will go to the museum to see the exhibit.\n",
      "By friend has a beautiful garden in her back yard.\n"
     ]
    }
   ],
   "source": [
    "correct_text_1 = TextBlob(incorrect_text_1)\n",
    "correct_text_2 = TextBlob(incorrect_text_2)\n",
    "correct_text_3 = TextBlob(incorrect_text_3)\n",
    "correct_text_4 = TextBlob(incorrect_text_4)\n",
    "correct_text_5 = TextBlob(incorrect_text_5)\n",
    "print(correct_text_1.correct().string)\n",
    "print(correct_text_2.correct().string)\n",
    "print(correct_text_3.correct().string)\n",
    "print(correct_text_4.correct().string)\n",
    "print(correct_text_5.correct().string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab52dc6",
   "metadata": {},
   "source": [
    "# Stopwords Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b753aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf08d4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05ec1a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user.LAPTOP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1c39495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i've come watching endgame must say disappoint...\n",
       "1       i've come watching endgame must say disappoint...\n",
       "2       i've come watching endgame must say disappoint...\n",
       "3       i've come watching endgame must say disappoint...\n",
       "4       i've come watching endgame must say disappoint...\n",
       "                              ...                        \n",
       "9509    i've come watching endgame must say disappoint...\n",
       "9510    i've come watching endgame must say disappoint...\n",
       "9511    i've come watching endgame must say disappoint...\n",
       "9512    i've come watching endgame must say disappoint...\n",
       "9513    i've come watching endgame must say disappoint...\n",
       "Name: Review, Length: 9514, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_review['Review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "114c4a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date of Review</th>\n",
       "      <th>User</th>\n",
       "      <th>Usefulness Vote</th>\n",
       "      <th>Total Votes</th>\n",
       "      <th>User's Rating out of 10</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 May 2019</td>\n",
       "      <td>paynebyname</td>\n",
       "      <td>1481</td>\n",
       "      <td>2771</td>\n",
       "      <td>4</td>\n",
       "      <td>The writers got carried away, the directors ov...</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 May 2019</td>\n",
       "      <td>jtindahouse</td>\n",
       "      <td>75</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "      <td>Time travel is such a lazy way to write stories</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13 May 2019</td>\n",
       "      <td>arclinecreative</td>\n",
       "      <td>100</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "      <td>Overrated and full of filler</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 August 2019</td>\n",
       "      <td>retrorick</td>\n",
       "      <td>99</td>\n",
       "      <td>169</td>\n",
       "      <td>3</td>\n",
       "      <td>downbeat, overblown &amp; so so long. Cuts all you...</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13 December 2021</td>\n",
       "      <td>acollegestudent</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>Not as good as infinity war but a great movie</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>1 June 2019</td>\n",
       "      <td>ismael_rivera</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>A reward to fans that have been since the begi...</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>27 April 2019</td>\n",
       "      <td>barbarasokoloski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Fun and well-done</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>25 April 2019</td>\n",
       "      <td>jfelipepoll</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Just Wao!!</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>25 April 2019</td>\n",
       "      <td>louikelemen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Endgame is for the Fans</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9513</th>\n",
       "      <td>26 April 2019</td>\n",
       "      <td>kayodeodusanya</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>BADASS!!!</td>\n",
       "      <td>i've just come from watching endgame and i mus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9514 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date of Review              User  Usefulness Vote  Total Votes  \\\n",
       "0           4 May 2019       paynebyname             1481         2771   \n",
       "1           6 May 2019       jtindahouse               75          127   \n",
       "2          13 May 2019   arclinecreative              100          170   \n",
       "3        3 August 2019         retrorick               99          169   \n",
       "4     13 December 2021   acollegestudent               27           41   \n",
       "...                ...               ...              ...          ...   \n",
       "9509       1 June 2019     ismael_rivera                0            2   \n",
       "9510     27 April 2019  barbarasokoloski                0            0   \n",
       "9511     25 April 2019       jfelipepoll                0            2   \n",
       "9512     25 April 2019       louikelemen                0            0   \n",
       "9513     26 April 2019    kayodeodusanya                0            2   \n",
       "\n",
       "     User's Rating out of 10  \\\n",
       "0                          4   \n",
       "1                          4   \n",
       "2                          3   \n",
       "3                          3   \n",
       "4                          8   \n",
       "...                      ...   \n",
       "9509                       9   \n",
       "9510                       8   \n",
       "9511                      10   \n",
       "9512                      10   \n",
       "9513                       9   \n",
       "\n",
       "                                           Review Title  \\\n",
       "0     The writers got carried away, the directors ov...   \n",
       "1       Time travel is such a lazy way to write stories   \n",
       "2                          Overrated and full of filler   \n",
       "3     downbeat, overblown & so so long. Cuts all you...   \n",
       "4         Not as good as infinity war but a great movie   \n",
       "...                                                 ...   \n",
       "9509  A reward to fans that have been since the begi...   \n",
       "9510                                  Fun and well-done   \n",
       "9511                                         Just Wao!!   \n",
       "9512                            Endgame is for the Fans   \n",
       "9513                                          BADASS!!!   \n",
       "\n",
       "                                                 Review  \n",
       "0     i've just come from watching endgame and i mus...  \n",
       "1     i've just come from watching endgame and i mus...  \n",
       "2     i've just come from watching endgame and i mus...  \n",
       "3     i've just come from watching endgame and i mus...  \n",
       "4     i've just come from watching endgame and i mus...  \n",
       "...                                                 ...  \n",
       "9509  i've just come from watching endgame and i mus...  \n",
       "9510  i've just come from watching endgame and i mus...  \n",
       "9511  i've just come from watching endgame and i mus...  \n",
       "9512  i've just come from watching endgame and i mus...  \n",
       "9513  i've just come from watching endgame and i mus...  \n",
       "\n",
       "[9514 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fb84a",
   "metadata": {},
   "source": [
    "# Remove and Delete Emoji in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "860ac604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    clean_text = emoji_pattern.sub(r'', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "238d7a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just finished my final exams!  Now it's time to relax and enjoy the summer ☀️️\n",
      "Pizza for dinner tonight \n",
      "Happy birthday! \n"
     ]
    }
   ],
   "source": [
    "print(remove_emojis(\"Just finished my final exams! 📚🎉 Now it's time to relax and enjoy the summer ☀️🏖️\"))\n",
    "print(remove_emojis('Pizza for dinner tonight 🍕😋'))\n",
    "print(remove_emojis('Happy birthday! 🎂🎉'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254f8ac",
   "metadata": {},
   "source": [
    "## Delete Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9244e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8661c6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Can't wait to see my family for the holidays! :Christmas_tree::wrapped_gift::smiling_face_with_smiling_eyes:\n",
      "2. :pizza::hamburger: Dinner time! Time to indulge in some delicious food! :french_fries::soft_ice_cream:\n",
      "3. Feeling so proud of my little sister for graduating today! :graduation_cap::party_popper: She's going to do amazing things! :flexed_biceps::woman_student:\n",
      "4.Just finished my final exams! :books::party_popper: Now it's time to relax and enjoy the summer :sun::beach_with_umbrella:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize(\"1. Can't wait to see my family for the holidays! 🎄🎁😊\"))\n",
    "\n",
    "print(emoji.demojize(\"2. 🍕🍔 Dinner time! Time to indulge in some delicious food! 🍟🍦\"))\n",
    "print(emoji.demojize(\"3. Feeling so proud of my little sister for graduating today! 🎓🎉 She's going to do amazing things! 💪👩‍🎓\"))\n",
    "print(emoji.demojize(\"4.Just finished my final exams! 📚🎉 Now it's time to relax and enjoy the summer ☀️🏖️\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817df186",
   "metadata": {},
   "source": [
    "# Tokinization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c7c4a",
   "metadata": {},
   "source": [
    "## Tokinization with split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0045f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"Python is a versatile and widely-used programming language known for its simplicity and readability, making it an excellent choice for beginners and experienced developers alike.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7879a677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'is',\n",
       " 'a',\n",
       " 'versatile',\n",
       " 'and',\n",
       " 'widely-used',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'known',\n",
       " 'for',\n",
       " 'its',\n",
       " 'simplicity',\n",
       " 'and',\n",
       " 'readability,',\n",
       " 'making',\n",
       " 'it',\n",
       " 'an',\n",
       " 'excellent',\n",
       " 'choice',\n",
       " 'for',\n",
       " 'beginners',\n",
       " 'and',\n",
       " 'experienced',\n",
       " 'developers',\n",
       " 'alike.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e425c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"ChatGPT is an AI-powered language model developed by OpenAI.It is based on the GPT-3.5 architecture and trained on a vast amount of text data.ChatGPT is designed to understand and generate human-like text responses.Users can interact with ChatGPT through a conversational interface, making it easy to engage in natural language conversations.ChatGPT has a wide range of applications, including chatbots, virtual assistants, and interactive content generation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93a5cfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatGPT is an AI-powered language model developed by OpenAI',\n",
       " 'It is based on the GPT-3',\n",
       " '5 architecture and trained on a vast amount of text data',\n",
       " 'ChatGPT is designed to understand and generate human-like text responses',\n",
       " 'Users can interact with ChatGPT through a conversational interface, making it easy to engage in natural language conversations',\n",
       " 'ChatGPT has a wide range of applications, including chatbots, virtual assistants, and interactive content generation',\n",
       " '']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff320a02",
   "metadata": {},
   "source": [
    "# Tokinization with NLTK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "263dd897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user.LAPTOP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b959a153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Kolkata']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_1 ='I am going to Kolkata'\n",
    "word_tokenize(sent_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40e00413",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_2 = '''I'm happy.\n",
    "She exercises every morning.\n",
    "His dog barks loudly.\n",
    "My school starts at 8:00.\n",
    "We always eat dinner together.\n",
    "They take the bus to work.\n",
    "He doesn't like vegetables.\n",
    "I don't want anything to drink.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e697643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm happy.\",\n",
       " 'She exercises every morning.',\n",
       " 'His dog barks loudly.',\n",
       " 'My school starts at 8:00.',\n",
       " 'We always eat dinner together.',\n",
       " 'They take the bus to work.',\n",
       " \"He doesn't like vegetables.\",\n",
       " \"I don't want anything to drink.\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sent_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b50e06f",
   "metadata": {},
   "source": [
    "# Steamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42717c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ed7ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def word_stem(text):\n",
    "    return ' '.join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "71ef94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtostem = 'talk talking talked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7cbafaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talk talk talk'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_stem(wordtostem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "791df3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_stem = '''This might be the most difficult decision she would ever make.\n",
    "It must be difficult for Alex to keep you happy. \n",
    "Then why was it so difficult to forgive him? ...\n",
    "I can only imagine how difficult this is for you. \n",
    "I sensed it was a difficult one on his part.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d975309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thi might be the most difficult decis she would ever make. it must be difficult for alex to keep you happy. then whi wa it so difficult to forgiv him? ... i can onli imagin how difficult thi is for you. i sens it wa a difficult one on hi part.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_stem(sent_to_stem)  # Here is fail to stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf8e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
